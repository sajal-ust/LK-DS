{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710023aa-c71e-442b-95e3-a44fbb37ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "976a9169-2e4d-4801-9179-370f639ebe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load dataset ---\n",
    "df = pd.read_csv(\"Augmented_Stockist_Data.csv\")\n",
    "\n",
    "# --- Compute Engagement Score ---\n",
    "df[\"Engagement_Score\"] = np.log1p(df[\"Sales_Value_Last_Period\"]) * (\n",
    "    df[\"Feedback_Score\"] + df[\"Growth_Percentage\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59153d05-9730-43e5-bdb2-348fb7639ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Train-test split ---\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df.to_csv(\"Train_Data.csv\", index=False)\n",
    "test_df.to_csv(\"Test_Data.csv\", index=False)\n",
    "# --- Partner × Scheme matrix ---\n",
    "item_scheme_matrix = train_df.pivot_table(\n",
    "    index=\"Partner_id\",\n",
    "    columns=\"Scheme_Type\",\n",
    "    values=\"Engagement_Score\",\n",
    "    aggfunc=\"mean\",\n",
    "    fill_value=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e584438-ed81-4941-b94d-93489edf9ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a459bcb3-9323-411c-b66f-df2050a6bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute dynamic threshold (mean of all non-zero scores) ---\n",
    "non_zero_scores = item_scheme_matrix[item_scheme_matrix > 0].stack()\n",
    "threshold = non_zero_scores.mean()\n",
    "\n",
    "# --- Binarize using dynamic threshold ---\n",
    "binary_scheme_matrix = (item_scheme_matrix >= threshold).astype(int)\n",
    "\n",
    "# --- Transpose to get Scheme × Partner matrix ---\n",
    "scheme_matrix = binary_scheme_matrix.T\n",
    "\n",
    "# --- Jaccard similarity between schemes ---\n",
    "similarity_matrix = pd.DataFrame(index=scheme_matrix.index, columns=scheme_matrix.index, dtype=float)\n",
    "\n",
    "for i in range(len(scheme_matrix)):\n",
    "    for j in range(len(scheme_matrix)):\n",
    "        if i != j:\n",
    "            similarity_matrix.iloc[i, j] = jaccard_score(\n",
    "                scheme_matrix.iloc[i].values, scheme_matrix.iloc[j].values\n",
    "            )\n",
    "        else:\n",
    "            similarity_matrix.iloc[i, j] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "326c7d49-f00d-46e3-b3de-5b504ba20dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Generate top-3 scheme recommendations per test pair ---\n",
    "recommendations = []\n",
    "test_pairs = test_df[[\"Partner_id\", \"Product_id\", \"Scheme_Type\"]].drop_duplicates()\n",
    "\n",
    "for _, row in test_pairs.iterrows():\n",
    "    partner = row[\"Partner_id\"]\n",
    "    product = row[\"Product_id\"]\n",
    "    current_scheme = row[\"Scheme_Type\"]\n",
    "\n",
    "    if current_scheme in similarity_matrix.index:\n",
    "        similar_schemes = similarity_matrix.loc[current_scheme].drop(current_scheme).sort_values(ascending=False).head(3)\n",
    "        sim_list = similar_schemes.index.tolist()\n",
    "\n",
    "        recommendations.append({\n",
    "            \"Partner_id\": partner,\n",
    "            \"Product_id\": product,\n",
    "            \"Similarity_Score\": round(similar_schemes.mean(), 6),\n",
    "            \"Scheme_1\": sim_list[0] if len(sim_list) > 0 else \"No Scheme\",\n",
    "            \"Scheme_2\": sim_list[1] if len(sim_list) > 1 else \"No Scheme\",\n",
    "            \"Scheme_3\": sim_list[2] if len(sim_list) > 2 else \"No Scheme\"\n",
    "        })\n",
    "    else:\n",
    "        print(f\"Scheme '{current_scheme}' not found in training data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6592263f-3483-4b5d-88cd-2ab40db94a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Partner_id                   Product_id  Similarity_Score         Scheme_1  \\\n",
      "0      P1067             Modular Switches          0.327193   Seasonal Offer   \n",
      "1      P1003                          AIS          0.332821   Seasonal Offer   \n",
      "2      P1003                          ACB          0.032517  Volume Discount   \n",
      "3      P1003                          VCU          0.342034         Cashback   \n",
      "4      P1063  Pump Starter and Controller          0.342034         Cashback   \n",
      "\n",
      "          Scheme_2         Scheme_3  \n",
      "0  Volume Discount  Loyalty Program  \n",
      "1         Cashback  Loyalty Program  \n",
      "2   Seasonal Offer  Loyalty Program  \n",
      "3  Volume Discount  Loyalty Program  \n",
      "4  Volume Discount  Loyalty Program  \n"
     ]
    }
   ],
   "source": [
    "# --- Save recommendations ---\n",
    "recommendation_df = pd.DataFrame(recommendations)\n",
    "recommendation_df.to_csv(\"Scheme_Recommendations.csv\", index=False)\n",
    "\n",
    "# --- Preview output ---\n",
    "print(recommendation_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8aa81-4474-4d8c-a151-995135d9de6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33453003-20b6-4c4d-a6ab-450c80c1e5aa",
   "metadata": {},
   "source": [
    "Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8832d289-9b61-465f-9ace-889b9d7e44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0fe33f2-1bb4-4076-993d-f1c834cfab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data (long format — one row per availed scheme per partner)\n",
    "test_df = pd.read_csv(\"Test_Data.csv\")\n",
    "\n",
    "# Load the recommendation data (top 3 recommended schemes per partner)\n",
    "rec_df = pd.read_csv(\"Scheme_Recommendations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a2f1cef-ece0-4836-ac3f-f76bc7ff84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Partner_id to get list of all availed schemes\n",
    "availed_df = (\n",
    "    test_df.groupby(\"Partner_id\")[\"Scheme_Type\"]\n",
    "    .apply(list)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"Scheme_Type\": \"Availed_Schemes\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4695eb28-a3c4-4d4e-9fb3-36e915778394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Scheme_1, Scheme_2, Scheme_3 into a single list column\n",
    "rec_df[\"Recommended_Schemes\"] = rec_df[[\"Scheme_1\", \"Scheme_2\", \"Scheme_3\"]].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bcc37d2-0f50-4df3-bb6e-e01759b75d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge availed and recommended schemes using Partner_id\n",
    "df_all = pd.merge(\n",
    "    availed_df,\n",
    "    rec_df[[\"Partner_id\", \"Recommended_Schemes\"]],\n",
    "    on=\"Partner_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure both lists are properly formatted\n",
    "df_all[\"Availed_Schemes\"] = df_all[\"Availed_Schemes\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "df_all[\"Recommended_Schemes\"] = df_all[\"Recommended_Schemes\"].apply(lambda x: x if isinstance(x, list) else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af1ff0e-2b28-4ee3-a081-959ecb0cfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "k_list = [1, 2, 3]\n",
    "results = []\n",
    "\n",
    "# Evaluate precision, recall, F1 for each Top-K level\n",
    "for k in k_list:\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "\n",
    "    for _, row in df_all.iterrows():\n",
    "        actual_set = set(row[\"Availed_Schemes\"])\n",
    "        recommended_k = row[\"Recommended_Schemes\"][:k]  # Top-K recommendations\n",
    "\n",
    "        if not actual_set:\n",
    "            continue  # skip if no availed schemes\n",
    "\n",
    "        # Count correct predictions in Top-K\n",
    "        tp = sum([1 for scheme in recommended_k if scheme in actual_set])\n",
    "        precision = tp / k\n",
    "        recall = tp / len(actual_set)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        \n",
    "    # Average the metrics across all partners\n",
    "    avg_precision = round(sum(precision_list) / len(precision_list), 4) if precision_list else 0\n",
    "    avg_recall = round(sum(recall_list) / len(recall_list), 4) if recall_list else 0\n",
    "    f1 = round(2 * avg_precision * avg_recall / (avg_precision + avg_recall), 4) if (avg_precision + avg_recall) else 0\n",
    "\n",
    "    results.append({\n",
    "        \"Top-K\": k,\n",
    "        \"Avg Precision\": avg_precision,\n",
    "        \"Avg Recall\": avg_recall,\n",
    "        \"Avg F1 Score\": f1\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b10fad62-d222-4079-ac16-c6ac3f4c511d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Per-Scheme Evaluation (WITH Availed Schemes) ====\n",
      "\n",
      "Top-1\n",
      "  Avg Precision : 0.9782\n",
      "  Avg Recall    : 0.2407\n",
      "  Avg F1 Score  : 0.3863\n",
      "\n",
      "Top-2\n",
      "  Avg Precision : 0.9823\n",
      "  Avg Recall    : 0.484\n",
      "  Avg F1 Score  : 0.6485\n",
      "\n",
      "Top-3\n",
      "  Avg Precision : 0.9875\n",
      "  Avg Recall    : 0.7312\n",
      "  Avg F1 Score  : 0.8402\n"
     ]
    }
   ],
   "source": [
    "# Print Top-K per-scheme evaluation metrics\n",
    "print(\"==== Per-Scheme Evaluation (WITH Availed Schemes) ====\")\n",
    "for r in results:\n",
    "    print(f\"\\nTop-{r['Top-K']}\")\n",
    "    print(f\"  Avg Precision : {r['Avg Precision']}\")\n",
    "    print(f\"  Avg Recall    : {r['Avg Recall']}\")\n",
    "    print(f\"  Avg F1 Score  : {r['Avg F1 Score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabff3ba-23ca-4a8b-8658-f6fe77bb839e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8128022-1aae-47af-b25e-58bbaebe7b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb4943-69e8-4297-92d2-a8563586b446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b112599-7efb-419f-abb6-456543daa3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
