{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b94982b-76e6-4a6b-a7e2-37764a91dcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Based Recommendations saved with Geography and Stockist_Type features.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\291688\\Downloads\\Scheme_Recommendation_Explainable_ai\\Dataset\\Augmented_Stockist_Data (1).csv\")\n",
    "\n",
    "# One-hot encoding for Geography and Stockist_Type\n",
    "df = pd.get_dummies(df, columns=[\"Geography\", \"Stockist_Type\"], dtype=int)\n",
    "\n",
    "# Identify geography and stockist type columns\n",
    "geo_columns = [col for col in df.columns if col.startswith(\"Geography\")]\n",
    "stockist_columns = [col for col in df.columns if col.startswith(\"Stockist_Type\")]\n",
    "\n",
    "if not geo_columns or not stockist_columns:\n",
    "    raise ValueError(\"No Geography or Stockist_Type features found after encoding! Check encoding step.\")\n",
    "\n",
    "# Ensure Sales_Value_Last_Period does not contain zeros to avoid log(0)\n",
    "df[\"Sales_Value_Last_Period\"] = df[\"Sales_Value_Last_Period\"].replace(0, 1)\n",
    "\n",
    "# Calculate Engagement Score\n",
    "df[\"Engagement_Score\"] = np.log1p(df[\"Sales_Value_Last_Period\"]) * (df[\"Feedback_Score\"] + df[geo_columns+stockist_columns].sum(axis=1))\n",
    "\n",
    "# Train-Test Split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Partner_id\"])\n",
    "\n",
    "# Pivot User-Scheme Matrix using Engagement Score\n",
    "user_scheme_matrix = train_df.pivot_table(\n",
    "    index=\"Partner_id\", columns=\"Scheme_Type\", values=\"Engagement_Score\", aggfunc=\"sum\", fill_value=0\n",
    ")\n",
    "\n",
    "# Add Geography & Stockist_Type Features\n",
    "user_features = train_df.groupby(\"Partner_id\")[geo_columns + stockist_columns].mean()  # Aggregate features per Partner_id\n",
    "user_scheme_matrix = user_scheme_matrix.merge(user_features, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "# Prepare sparse matrix\n",
    "user_scheme_sparse = csr_matrix(user_scheme_matrix.values)\n",
    "\n",
    "partner_id_lookup = list(user_scheme_matrix.index)\n",
    "\n",
    "# Fit Nearest Neighbors (Cosine Similarity)\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(user_scheme_sparse)\n",
    "\n",
    "# Recommendation Function\n",
    "def recommend_user_based(partner_id, top_n=3):\n",
    "    if partner_id not in user_scheme_matrix.index:\n",
    "        return None\n",
    "\n",
    "    idx = partner_id_lookup.index(partner_id)\n",
    "    distances, indices = knn_model.kneighbors(user_scheme_sparse[idx], n_neighbors=min(top_n + 1, len(user_scheme_matrix)))\n",
    "    similarities = 1 - distances.flatten()\n",
    "    neighbors = indices.flatten()\n",
    "\n",
    "    filtered = [(i, sim) for i, sim in zip(neighbors, similarities) if i != idx]\n",
    "    if not filtered:\n",
    "        return None\n",
    "\n",
    "    top_idx, sim_score = filtered[0]\n",
    "    similar_user = partner_id_lookup[top_idx]\n",
    "    sim_score = round(sim_score, 6)\n",
    "\n",
    "    top_schemes = (\n",
    "        train_df[train_df[\"Partner_id\"] == similar_user][\"Scheme_Type\"]\n",
    "        .value_counts().head(3).index.tolist()\n",
    "    )\n",
    "    while len(top_schemes) < 3:\n",
    "        top_schemes.append(\"No Scheme\")\n",
    "\n",
    "    product = train_df[train_df[\"Partner_id\"] == partner_id][\"Product_id\"].unique()[0]\n",
    "\n",
    "    return [partner_id, product, sim_score, *top_schemes]\n",
    "\n",
    "# Generate Recommendations\n",
    "user_partners = test_df[\"Partner_id\"].unique()\n",
    "user_recommendations = [recommend_user_based(pid) for pid in user_partners if recommend_user_based(pid)]\n",
    "\n",
    "# Save Output\n",
    "user_rec_df = pd.DataFrame(user_recommendations, columns=[\"Partner_id\", \"Product_id\", \"Similarity_Score\", \"Scheme_1\", \"Scheme_2\", \"Scheme_3\"])\n",
    "user_rec_df.to_csv(\"user_based_recommendations_with_geography_stockist.csv\", index=False)\n",
    "\n",
    "print(\"User-Based Recommendations saved with Geography and Stockist_Type features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d8c69a5-3502-46c0-8b60-dd085fb3987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Importance (Higher means more impact on recommendations):\n",
      "Geography Feature Importance:\n",
      "Geography_South    0.079208\n",
      "Geography_West     0.073267\n",
      "Geography_East     0.069307\n",
      "Geography_North    0.069307\n",
      "dtype: float64\n",
      "\n",
      "Stockist_Type Feature Importance:\n",
      "Stockist_Type_Retailer       0.10297\n",
      "Stockist_Type_Wholesaler     0.10099\n",
      "Stockist_Type_Distributor    0.09505\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def compute_feature_importance(feature_columns, num_shuffles=5, random_seed=42):\n",
    "    importance_scores = {feature: [] for feature in feature_columns}\n",
    "\n",
    "    # Generate Baseline Recommendations\n",
    "    baseline_recommendations = {\n",
    "        pid: recommend_user_based(pid) for pid in test_df[\"Partner_id\"].unique()\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    baseline_df = pd.DataFrame(\n",
    "        [v for v in baseline_recommendations.values() if v],\n",
    "        columns=[\"Partner_id\", \"Product_id\", \"Similarity_Score\", \"Scheme_1\", \"Scheme_2\", \"Scheme_3\"]\n",
    "    ).set_index([\"Partner_id\", \"Product_id\"])\n",
    "\n",
    "    for feature in feature_columns:\n",
    "        for i in range(num_shuffles):\n",
    "            perturbed_df = deepcopy(df)\n",
    "            \n",
    "            #  Set Random Seed for Stability in Each Shuffle\n",
    "            np.random.seed(random_seed + i)\n",
    "            perturbed_df[feature] = np.random.permutation(perturbed_df[feature].values)\n",
    "\n",
    "            # Train-Test Split Again\n",
    "            train_df_perturbed = perturbed_df.loc[train_df.index]\n",
    "\n",
    "            # Recompute Engagement Score\n",
    "            train_df_perturbed[\"Engagement_Score\"] = np.log1p(train_df_perturbed[\"Sales_Value_Last_Period\"]) * (\n",
    "                train_df_perturbed[\"Feedback_Score\"] + train_df_perturbed[geo_columns + stockist_columns].sum(axis=1)\n",
    "            )\n",
    "\n",
    "            # Pivot User-Scheme Matrix\n",
    "            user_scheme_matrix_perturbed = train_df_perturbed.pivot_table(\n",
    "                index=\"Partner_id\", columns=\"Scheme_Type\", values=\"Engagement_Score\", aggfunc=\"sum\", fill_value=0\n",
    "            )\n",
    "\n",
    "            # Add Geography & Stockist_Type Features\n",
    "            user_features_perturbed = train_df_perturbed.groupby(\"Partner_id\")[geo_columns + stockist_columns].sum()\n",
    "            user_scheme_matrix_perturbed = user_scheme_matrix_perturbed.merge(\n",
    "                user_features_perturbed, left_index=True, right_index=True, how=\"left\"\n",
    "            )\n",
    "\n",
    "            # Prepare sparse matrix and retrain KNN\n",
    "            user_scheme_sparse_perturbed = csr_matrix(user_scheme_matrix_perturbed.values)\n",
    "            knn_model.fit(user_scheme_sparse_perturbed)\n",
    "\n",
    "            # Generate New Recommendations\n",
    "            perturbed_recommendations = {\n",
    "                pid: recommend_user_based(pid) for pid in test_df[\"Partner_id\"].unique()\n",
    "            }\n",
    "\n",
    "            # Convert to DataFrame\n",
    "            perturbed_df = pd.DataFrame(\n",
    "                [v for v in perturbed_recommendations.values() if v],\n",
    "                columns=[\"Partner_id\", \"Product_id\", \"Similarity_Score\", \"Scheme_1\", \"Scheme_2\", \"Scheme_3\"]\n",
    "            ).set_index([\"Partner_id\", \"Product_id\"])\n",
    "\n",
    "            # Compare Recommendations (Count only rows where all three schemes changed)\n",
    "            scheme_columns = [\"Scheme_1\", \"Scheme_2\", \"Scheme_3\"]\n",
    "            changed_recommendations = (baseline_df[scheme_columns] != perturbed_df[scheme_columns]).all(axis=1)\n",
    "            changed_count = changed_recommendations.sum()\n",
    "\n",
    "            # Normalize by total recommendations in baseline\n",
    "            importance_scores[feature].append(changed_count / len(baseline_df))\n",
    "\n",
    "    # Compute average importance score over multiple shuffles\n",
    "    avg_importance_scores = {feature: np.mean(scores) for feature, scores in importance_scores.items()}\n",
    "\n",
    "    return avg_importance_scores\n",
    "\n",
    "# Compute Feature Importance for Geography & Stockist_Type\n",
    "geo_importance = compute_feature_importance(geo_columns, num_shuffles=5, random_seed=42)\n",
    "stockist_importance = compute_feature_importance(stockist_columns, num_shuffles=5, random_seed=42)\n",
    "\n",
    "# Print Results\n",
    "print(\"\\nFeature Importance (Higher means more impact on recommendations):\")\n",
    "print(\"Geography Feature Importance:\")\n",
    "print(pd.Series(geo_importance).sort_values(ascending=False))\n",
    "\n",
    "print(\"\\nStockist_Type Feature Importance:\")\n",
    "print(pd.Series(stockist_importance).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051d062-73ed-4a66-8602-a1fb5d0e0732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
