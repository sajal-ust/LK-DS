{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89423f0-0dfb-4192-811c-5c62d652b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9eadd7e-b256-4c75-b187-7c1b96506b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Logging Setup -----------------------\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s — %(levelname)s — %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a438afed-ac06-4ec6-b3fb-c3f524479687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------- Functions -----------------------\n",
    "\n",
    "def load_and_prepare_data(filepath):\n",
    "    logger.info(\"Loading dataset...\")\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    logger.info(\"Calculating Engagement Score...\")\n",
    "    df[\"Engagement_Score\"] = np.log1p(df[\"Sales_Value_Last_Period\"]) * (\n",
    "        df[\"Feedback_Score\"] + df[\"Growth_Percentage\"]\n",
    "    )\n",
    "    logger.info(\"Engagement Score calculated.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b1eeae-2edb-4e7d-a6ad-430cb87a1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    logger.info(\"Splitting data into train and test sets...\")\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"Partner_id\"])\n",
    "    logger.info(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b3935e-a87d-4a1e-b0f0-b3405df6a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def encode_and_clean_stockist_data(df):\n",
    "#     \"\"\"\n",
    "#     One-hot encodes 'Geography' and 'Stockist_Type' columns,\n",
    "#     validates their presence post-encoding, and ensures that\n",
    "#     'Sales_Value_Last_Period' has no zeros to prevent log(0) errors.\n",
    "\n",
    "#     Parameters:\n",
    "#         df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: Preprocessed DataFrame.\n",
    "#         list: Encoded geography column names.\n",
    "#         list: Encoded stockist type column names.\n",
    "#     \"\"\"\n",
    "#     # One-hot encoding\n",
    "#     df = pd.get_dummies(df, columns=[\"Geography\", \"Stockist_Type\"], dtype=int)\n",
    "\n",
    "#     # Identify encoded columns\n",
    "#     geo_columns = [col for col in df.columns if col.startswith(\"Geography_\")]\n",
    "#     stockist_columns = [col for col in df.columns if col.startswith(\"Stockist_Type_\")]\n",
    "\n",
    "#     # Validate that the encoding worked\n",
    "#     if not geo_columns or not stockist_columns:\n",
    "#         raise ValueError(\"No Geography or Stockist_Type features found after encoding! Check encoding step.\")\n",
    "\n",
    "#     # Handle potential zero values in sales\n",
    "#     if \"Sales_Value_Last_Period\" in df.columns:\n",
    "#         df[\"Sales_Value_Last_Period\"] = df[\"Sales_Value_Last_Period\"].replace(0, 1)\n",
    "\n",
    "#     return df, geo_columns, stockist_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764e320a-4d22-4937-9674-a8021bfd3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_user_scheme_matrix(train_df):\n",
    "#     logger.info(\"Creating user-scheme matrix...\")\n",
    "#     matrix = train_df.pivot_table(\n",
    "#         index=\"Partner_id\", columns=\"Scheme_Type\", values=\"Engagement_Score\", aggfunc=\"sum\", fill_value=0\n",
    "#     )\n",
    "#     logger.info(f\"User-Scheme matrix shape: {matrix.shape}\")\n",
    "#     return matrix\n",
    "def create_user_scheme_matrix(train_df):\n",
    "    logger.info(\"Creating user-scheme matrix using average engagement score...\")\n",
    "    matrix = train_df.pivot_table(\n",
    "        index=\"Partner_id\", columns=\"Scheme_Type\", values=\"Engagement_Score\", aggfunc=\"mean\", fill_value=0\n",
    "    )\n",
    "    logger.info(f\"User-Scheme matrix shape: {matrix.shape}\")\n",
    "    return matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71522c92-535f-44a1-bbdd-995c1300876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_knn_model(matrix):\n",
    "    logger.info(\"Preparing sparse matrix and fitting NearestNeighbors model...\")\n",
    "    sparse_matrix = csr_matrix(matrix.values)\n",
    "    knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    knn_model.fit(sparse_matrix)\n",
    "    logger.info(\"KNN model fitted.\")\n",
    "    return knn_model, sparse_matrix, list(matrix.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb3740e9-7a46-4e31-814b-c3d08b71d072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_user_based(partner_id, train_df, matrix, sparse_matrix, knn_model, id_lookup, top_n=3):\n",
    "    if partner_id not in matrix.index:\n",
    "        logger.warning(f\"Partner ID {partner_id} not found in training data.\")\n",
    "        return None\n",
    "\n",
    "    idx = id_lookup.index(partner_id)\n",
    "    distances, indices = knn_model.kneighbors(sparse_matrix[idx], n_neighbors=min(top_n + 1, len(matrix)))\n",
    "    similarities = 1 - distances.flatten()\n",
    "    neighbors = indices.flatten()\n",
    "\n",
    "    filtered = [(i, sim) for i, sim in zip(neighbors, similarities) if i != idx]\n",
    "    if not filtered:\n",
    "        logger.debug(f\"No similar users found for Partner ID {partner_id}.\")\n",
    "        return None\n",
    "\n",
    "    top_idx, sim_score = filtered[0]\n",
    "    similar_user = id_lookup[top_idx]\n",
    "    sim_score = round(sim_score, 6)\n",
    "\n",
    "    top_schemes = (\n",
    "        train_df[train_df[\"Partner_id\"] == similar_user][\"Scheme_Type\"]\n",
    "        .value_counts().head(3).index.tolist()\n",
    "    )\n",
    "\n",
    "    while len(top_schemes) < 3:\n",
    "        top_schemes.append(\"No Scheme\")\n",
    "\n",
    "    product = train_df[train_df[\"Partner_id\"] == partner_id][\"Product_id\"].unique()[0]\n",
    "\n",
    "    return [partner_id, product, sim_score, *top_schemes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86e7dba4-2f69-4f1b-8ade-56a5cbbf5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_recommendations(test_df, train_df, matrix, sparse_matrix, knn_model, id_lookup):\n",
    "    logger.info(\"Generating recommendations for test users...\")\n",
    "    user_partners = test_df[\"Partner_id\"].unique()\n",
    "    recommendations = []\n",
    "\n",
    "    for pid in user_partners:\n",
    "        rec = recommend_user_based(pid, train_df, matrix, sparse_matrix, knn_model, id_lookup)\n",
    "        if rec:\n",
    "            recommendations.append(rec)\n",
    "\n",
    "    logger.info(f\"Generated {len(recommendations)} recommendations.\")\n",
    "    return pd.DataFrame(recommendations, columns=[\"Partner_id\", \"Product_id\", \"Similarity_Score\", \"Scheme_1\", \"Scheme_2\", \"Scheme_3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1abae363-d0f0-47f9-a963-0f44afbc4217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_recommendations(df, output_path):\n",
    "    logger.info(f\"Saving recommendations to {output_path}...\")\n",
    "    df.to_csv(output_path, index=False)\n",
    "    logger.info(\"Recommendations saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0a373f-6217-49df-80fe-62f3cf0cd19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 13:09:27,644 — INFO — Loading dataset...\n",
      "2025-04-17 13:09:27,697 — INFO — Calculating Engagement Score...\n",
      "2025-04-17 13:09:27,700 — INFO — Engagement Score calculated.\n",
      "2025-04-17 13:09:27,701 — INFO — Splitting data into train and test sets...\n",
      "2025-04-17 13:09:27,730 — INFO — Train size: 16000, Test size: 4000\n",
      "2025-04-17 13:09:27,731 — INFO — Creating user-scheme matrix using average engagement score...\n",
      "2025-04-17 13:09:27,749 — INFO — User-Scheme matrix shape: (101, 5)\n",
      "2025-04-17 13:09:27,750 — INFO — Preparing sparse matrix and fitting NearestNeighbors model...\n",
      "2025-04-17 13:09:27,751 — INFO — KNN model fitted.\n",
      "2025-04-17 13:09:27,753 — INFO — Generating recommendations for test users...\n",
      "2025-04-17 13:09:28,359 — INFO — Generated 101 recommendations.\n",
      "2025-04-17 13:09:28,361 — INFO — Saving recommendations to user_based_recommendations_enhanced.csv...\n",
      "2025-04-17 13:09:28,375 — INFO — Recommendations saved successfully.\n",
      "2025-04-17 13:09:28,376 — INFO — User-based recommendation pipeline completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- Main Pipeline -----------------------\n",
    "\n",
    "def main(filepath, output_path=\"user_based_recommendations_enhanced.csv\"):\n",
    "    try:\n",
    "        df = load_and_prepare_data(filepath)\n",
    "        train_df, test_df = split_data(df)\n",
    "        matrix = create_user_scheme_matrix(train_df)\n",
    "        knn_model, sparse_matrix, id_lookup = fit_knn_model(matrix)\n",
    "        recommendation_df = generate_user_recommendations(test_df, train_df, matrix, sparse_matrix, knn_model, id_lookup)\n",
    "        save_recommendations(recommendation_df, output_path)\n",
    "        logger.info(\"User-based recommendation pipeline completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Pipeline failed: {e}\")\n",
    "\n",
    "# ----------------------- Script Entry Point -----------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(\"Augmented_Stockist_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195d44bc-d089-4f80-8486-85fe701638f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eefada9-925b-45b6-9c7c-3e48cb7ff2bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab8f0a3-5db6-4bb9-bb78-ad34690648fc",
   "metadata": {},
   "source": [
    "Evaluation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9992b9c-6d46-4cd6-9f14-8fbab0115341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f0362bb-deac-4489-8eb6-b87e533c920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_scheme_data(test_path: str, reco_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads, prepares, and merges availed schemes and recommended schemes for each partner.\n",
    "\n",
    "    Parameters:\n",
    "        test_path (str): Path to the test data CSV file (long format).\n",
    "        reco_path (str): Path to the recommendation CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with Partner_id, Availed_Schemes, Recommended_Schemes.\n",
    "    \"\"\"\n",
    "    # Load input files\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    rec_df = pd.read_csv(reco_path)\n",
    "\n",
    "    # Group test data by Partner_id to get list of availed schemes\n",
    "    availed_df = (\n",
    "        test_df.groupby(\"Partner_id\")[\"Scheme_Type\"]\n",
    "        .apply(list)\n",
    "        .reset_index()\n",
    "        .rename(columns={\"Scheme_Type\": \"Availed_Schemes\"})\n",
    "        )\n",
    "\n",
    "    # Combine Scheme_1, Scheme_2, Scheme_3 into a list column\n",
    "    rec_df['Recommended_Schemes'] = rec_df[['Scheme_1', 'Scheme_2', 'Scheme_3']].values.tolist()\n",
    "\n",
    "    # Merge both dataframes on Partner_id\n",
    "    df_all = pd.merge(\n",
    "        availed_df,\n",
    "        rec_df[['Partner_id', 'Recommended_Schemes']],\n",
    "        on='Partner_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # Ensure lists are well-formed\n",
    "    df_all['Availed_Schemes'] = df_all['Availed_Schemes'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    df_all['Recommended_Schemes'] = df_all['Recommended_Schemes'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    return df_all\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b329736a-cdd3-4f15-a60d-aa0cbe5de7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_per_scheme(df: pd.DataFrame, recommendation_col: str = 'Recommended_Schemes', k_list=[1, 2, 3]) -> list:\n",
    "    \"\"\"\n",
    "    Evaluates per-scheme Top-K precision, recall, and F1 score.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with availed and recommended schemes per partner.\n",
    "        recommendation_col (str): Column name of the recommendation list.\n",
    "        k_list (list): List of Top-K values to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries with metrics per K.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for k in k_list:\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            actual_set = set(row['Availed_Schemes'])\n",
    "            recommended_k = row[recommendation_col][:k]  # Do not use set here!\n",
    "\n",
    "            if not actual_set:\n",
    "                continue  # Skip if no ground truth\n",
    "\n",
    "            # Count number of correct schemes in Top-K\n",
    "            tp = sum([1 for scheme in recommended_k if scheme in actual_set])\n",
    "            precision = tp / k\n",
    "            recall = tp / len(actual_set)\n",
    "\n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "\n",
    "        # Average metrics\n",
    "        avg_precision = round(sum(precision_list) / len(precision_list), 4) if precision_list else 0\n",
    "        avg_recall = round(sum(recall_list) / len(recall_list), 4) if recall_list else 0\n",
    "        f1 = round(2 * avg_precision * avg_recall / (avg_precision + avg_recall), 4) if (avg_precision + avg_recall) else 0\n",
    "\n",
    "        results.append({\n",
    "            \"Top-K\": k,\n",
    "            \"Avg Precision\": avg_precision,\n",
    "            \"Avg Recall\": avg_recall,\n",
    "            \"Avg F1 Score\": f1\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cb8b99-7e5f-4810-8367-736a5ae26355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the data\n",
    "test_path = \"test_data.csv\"\n",
    "reco_path = \"user_based_recommendations_enhanced.csv\"\n",
    "\n",
    "df_all = prepare_scheme_data(test_path, reco_path)\n",
    "\n",
    "# Run per-scheme evaluation (no filtering of availed schemes)\n",
    "results = evaluate_per_scheme(df_all, recommendation_col='Recommended_Schemes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a9549b-5683-4795-b856-5b8e25fca652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Top-K': 1,\n",
       "  'Avg Precision': 0.9802,\n",
       "  'Avg Recall': 0.2452,\n",
       "  'Avg F1 Score': 0.3923},\n",
       " {'Top-K': 2,\n",
       "  'Avg Precision': 0.9851,\n",
       "  'Avg Recall': 0.4937,\n",
       "  'Avg F1 Score': 0.6578},\n",
       " {'Top-K': 3,\n",
       "  'Avg Precision': 0.9901,\n",
       "  'Avg Recall': 0.7455,\n",
       "  'Avg F1 Score': 0.8506}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab04e92-5f9f-4c90-9fb1-73134bc5e11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
