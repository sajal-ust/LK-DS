# -*- coding: utf-8 -*-
"""Indirect_Lambda_Handler.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tPWAuvgRPnvPc0BcHvIePBDvMCeAMEYd
"""

import os
import logging
import boto3
import pandas as pd
import numpy as np
import ast
from io import BytesIO
from collections import Counter
from scipy.optimize import linprog
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import pairwise_distances
from sklearn.neighbors import NearestNeighbors

# -------------------- Logging Setup --------------------
logger = logging.getLogger()
logger.setLevel(logging.INFO)
if not logger.handlers:
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

# -------------------- ENV Config --------------------
active_approach = os.getenv("ACTIVE_APPROACH", "item_based")
analysis_mode = os.getenv("ANALYSIS_MODE", "simple")
is_lambda = os.getenv("IS_LAMBDA", "false").lower() == "true"

s3_client = boto3.client("s3")
input_bucket = "lk-scheme-recommendations"
output_bucket = "lk-scheme-recommendations"

# -------------------- I/O Helpers --------------------
def load_file(path_or_key):
    if is_lambda:
        logger.info(f"Loading from S3: {path_or_key}")
        response = s3_client.get_object(Bucket=input_bucket, Key=path_or_key)
        return pd.read_csv(BytesIO(response['Body'].read()))
    else:
        logger.info(f"Loading locally: {path_or_key}")
        return pd.read_csv(path_or_key)

def save_file(df, path_or_key):
    if is_lambda:
        logger.info(f"Saving to S3: {path_or_key}")
        buffer = BytesIO()
        df.to_csv(buffer, index=False)
        buffer.seek(0)
        s3_client.put_object(Bucket=output_bucket, Key=path_or_key, Body=buffer)
    else:
        logger.info(f"Saving locally: {path_or_key}")
        df.to_csv(path_or_key, index=False)

# -------------------- Shared Variables --------------------
product_cols = [
    "AIS(Air Insulated Switchgear)", "RMU(Ring Main Unit)", "PSS(Compact Sub-Stations)",
    "VCU(Vacuum Contactor Units)", "E-House", "VCB(Vacuum Circuit Breaker)",
    "ACB(Air Circuit Breaker)", "MCCB(Moduled Case Circuit Breaker)", "SDF(Switch Disconnectors)",
    "BBT(Busbar Trunking)", "Modular Switches", "Starter", "Controller",
    "Solar Solutions", "Pump Starter and Controller"
]

# -------------------- Product Recommendation --------------------
def generate_user_recommendations(df):
    user_product_matrix = df.set_index("Partner_id")[product_cols].astype(int)
    knn = NearestNeighbors(metric='cosine', algorithm='brute')
    knn.fit(user_product_matrix)

    recommendations_with_scores = []
    for partner_id in df["Partner_id"]:
        if partner_id not in user_product_matrix.index:
            recommendations_with_scores.append([partner_id, [], []])
            continue
        distances, indices = knn.kneighbors(user_product_matrix.loc[[partner_id]], n_neighbors=6)
        similar_users = user_product_matrix.iloc[indices[0][1:]]
        similarity_scores = 1 - distances[0][1:]
        recommended_products = similar_users.T.dot(similarity_scores).sort_values(ascending=False)
        already_purchased = user_product_matrix.loc[partner_id]
        recommended_products = recommended_products[~already_purchased.astype(bool)]
        top_recs = list(recommended_products.head(3).index)
        top_scores = list(recommended_products.head(3).values)
        recommendations_with_scores.append([partner_id, top_recs, top_scores])

    user_df = pd.DataFrame(recommendations_with_scores, columns=["Partner_id", "Recommended_Products", "Similarity_Scores"])
    save_file(user_df, "User_Based_Recommendations.csv")

# -------------------- LP Scheme Mapping --------------------
def run_lp_scheme_mapping(df):
    metadata_cols = ['Partner_id', 'Geography', 'Stockist_Type', 'Scheme_Type', 'Sales_Value_Last_Period',
                     'Sales_Quantity_Last_Period', 'MRP', 'Growth_Percentage', 'Discount_Applied',
                     'Bulk_Purchase_Tendency', 'New_Stockist', 'Feedback_Score']
    product_cols_actual = [col for col in df.columns if col not in metadata_cols]
    melted = df.melt(id_vars=metadata_cols, value_vars=product_cols_actual,
                     var_name='Product_id', value_name='Has_Product')
    melted = melted[melted['Has_Product'] == 1].drop(columns=['Has_Product'])
    grouped = melted.groupby(["Partner_id", "Product_id", "Scheme_Type"]).agg({
        "Sales_Value_Last_Period": "sum",
        "Sales_Quantity_Last_Period": "sum"
    }).reset_index()
    opt_data = grouped[["Product_id", "Scheme_Type", "Sales_Value_Last_Period"]]

    def optimize(group):
        schemes = group["Scheme_Type"].unique()
        if len(schemes) <= 3:
            return list(schemes) + [None] * (3 - len(schemes))
        c = -group.groupby("Scheme_Type")["Sales_Value_Last_Period"].sum().values
        bounds = [(0, 1)] * len(schemes)
        linprog(c, bounds=bounds, method='highs')  # actual result not used here
        return [None, None, None]

    result = opt_data.groupby("Product_id").apply(optimize).reset_index()
    result[["Scheme_1", "Scheme_2", "Scheme_3"]] = pd.DataFrame(result[0].tolist(), index=result.index)
    result = result.drop(columns=[0])
    partners = melted.groupby("Product_id")["Partner_id"].apply(list).reset_index()
    merged = partners.merge(result, on="Product_id", how="left")
    save_file(merged, "Optimized_Product_Partner_Scheme_Mapping.csv")

# -------------------- Simple Scheme Mapping --------------------
def run_simple_scheme_mapping(df):
    output = []
    for product in product_cols:
        product_df = df[df[product] == 1]
        if product_df.empty:
            continue
        partner_ids = product_df['Partner_id'].dropna().astype(str).unique()
        scheme_data = product_df[['Scheme_Type', 'Sales_Quantity_Last_Period']].dropna()
        counter = Counter()
        for _, row in scheme_data.iterrows():
            schemes = row['Scheme_Type'].split(', ') if isinstance(row['Scheme_Type'], str) else []
            for scheme in schemes:
                counter[scheme] += row['Sales_Quantity_Last_Period']
        top_schemes = [s[0] for s in counter.most_common(3)] + ["No Scheme Available"] * 3
        output.append({
            'Product_id': product,
            'Partner_id': list(partner_ids),
            'Scheme_1': top_schemes[0],
            'Scheme_2': top_schemes[1],
            'Scheme_3': top_schemes[2]
        })
    save_file(pd.DataFrame(output), "Optimized_Product_Partner_Scheme_Mapping.csv")

# -------------------- Final Mapping --------------------
def generate_final_mapping(output_reco_file):
    df_scheme = load_file("Optimized_Product_Partner_Scheme_Mapping.csv")
    df_reco = load_file(output_reco_file)

    def safe_eval(val):
        try:
            return ast.literal_eval(val) if isinstance(val, str) and val.startswith("[") else val
        except:
            return val

    df_scheme.columns = df_scheme.columns.str.strip().str.lower()
    df_reco.columns = df_reco.columns.str.strip().str.lower()
    df_scheme["partner_id"] = df_scheme["partner_id"].apply(safe_eval)
    df_reco["recommended_products"] = df_reco["recommended_products"].apply(safe_eval)
    df_reco["similarity_scores"] = df_reco["similarity_scores"].apply(safe_eval)

    results = []
    for _, row in df_reco.iterrows():
        for product, score in zip(row["recommended_products"], row["similarity_scores"]):
            schemes = df_scheme[df_scheme["product_id"] == product][["scheme_1", "scheme_2", "scheme_3"]]
            if not schemes.empty:
                scheme_1, scheme_2, scheme_3 = schemes.iloc[0].fillna("Not Available").values
            else:
                scheme_1 = scheme_2 = scheme_3 = "Not Available"
            results.append([row["partner_id"], product, score, scheme_1, scheme_2, scheme_3])

    df_final = pd.DataFrame(results, columns=["Partner_id", "Product_id", "Similarity_Scores", "Scheme_1", "Scheme_2", "Scheme_3"])
    save_file(df_final, "Final_Partner_Product_Schemes.csv")

# -------------------- Lambda Handler --------------------
def lambda_handler(event, context):
    try:
        df = load_file("stockist_data.csv")

        if active_approach == "user_based":
            generate_user_recommendations(df)
            output_file = "User_Based_Recommendations.csv"
        elif active_approach == "item_based":
            generate_user_recommendations(df)  # Uses same recommender logic
            output_file = "Partner_Product_Recommendations.csv"
        else:
            raise ValueError("Invalid ACTIVE_APPROACH")

        if analysis_mode == "lp":
            run_lp_scheme_mapping(df)
        elif analysis_mode == "simple":
            run_simple_scheme_mapping(df)
        else:
            raise ValueError("Invalid ANALYSIS_MODE")

        generate_final_mapping(output_file)

        logger.info("Execution completed successfully.")
        return {"statusCode": 200, "body": "Execution completed successfully."}

    except Exception as e:
        logger.error(f"Error in Lambda execution: {str(e)}")
        return {"statusCode": 500, "body": str(e)}

# -------------------- Local Debug --------------------
if __name__ == "__main__":
    os.environ["IS_LAMBDA"] = "false"
    os.environ["ACTIVE_APPROACH"] = "user_based"  # or item_based
    os.environ["ANALYSIS_MODE"] = "simple"  # or lp
    print(lambda_handler({}, None))

# -------------------- Local Debug --------------------
if __name__ == "__main__":
    os.environ["IS_LAMBDA"] = "false"
    os.environ["ACTIVE_APPROACH"] = "user_based"  #
    os.environ["ANALYSIS_MODE"] = "lp"  #
    print(lambda_handler({}, None))

# -------------------- Local Debug --------------------
if __name__ == "__main__":
    os.environ["IS_LAMBDA"] = "false"
    os.environ["ACTIVE_APPROACH"] = "item_based"  # or item_based
    os.environ["ANALYSIS_MODE"] = "simple"  # or lp
    print(lambda_handler({}, None))

# -------------------- Local Debug --------------------
if __name__ == "__main__":
    os.environ["IS_LAMBDA"] = "false"
    os.environ["ACTIVE_APPROACH"] = "item_based"  # or item_based
    os.environ["ANALYSIS_MODE"] = "lp"  # or lp
    print(lambda_handler({}, None))

