import openai
import numpy as np
from lime.lime_text import LimeTextExplainer
import pandas as pd
from dotenv import load_dotenv
load_dotenv()
import os

openai.api_key = os.getenv("OPENAI_API_KEY")

# Define prediction function
def gpt_sentiment_predict(text):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": f"Classify this text as Positive or Negative: '{text}'"}
        ],
        temperature=0
    )
    return response["choices"][0]["message"]["content"].strip()

# Probability-like wrapper
def gpt_predict_proba(texts):
    preds = []
    for text in texts:
        label = gpt_sentiment_predict(text)
        if "Positive" in label:
            preds.append([0.1, 0.9])
        elif "Negative" in label:
            preds.append([0.9, 0.1])
        else:
            preds.append([0.5, 0.5])
    return np.array(preds)

# Load and sample data
base_dir = base_dir = os.getcwd() #os.path.dirname(__file__)  # Gets the current script's directory
df = os.path.join(base_dir,"LKEA-AI-Project","Sentiment_Analysis_NLP_Model", "input_data", "new_channel_partner_feedback.csv")

sample_texts = df["Feedback_Text"].dropna().sample(4, random_state=42).tolist()

# Initialize LIME explainer
explainer = LimeTextExplainer(class_names=["Negative", "Positive"])

# Explain each sample
for i, text in enumerate(sample_texts):
    print(f"\n--- Explanation for sample {i+1} ---\n{text}\n")
    exp = explainer.explain_instance(text, gpt_predict_proba, num_features=10, num_samples=50)
    exp.show_in_notebook()
