{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49533b44-483c-4b79-a3ea-d032e73343ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn.functional import softmax\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1e14c-3c85-47c3-aa1d-ce6d8be11c0a",
   "metadata": {},
   "source": [
    "load the pre-trained RoBERTa model and its tokenizer. The `AutoTokenizer` and `AutoModelForSequenceClassification` classes from the `transformers` library are used to load the model, which is fine-tuned for sentiment analysis on social media text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60cd851-1e98-47be-a277-2548a86b297b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load RoBERTa Sentiment Analysis Model\n",
    "roberta_model_name = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(roberta_model_name)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_model_name)\n",
    "roberta_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d3b5a-2a22-4674-b7f8-e12e6199c8ee",
   "metadata": {},
   "source": [
    "The function `analyze_roberta_sentiment()` takes text input, tokenizes it using the RoBERTa tokenizer, and passes it through the model to get sentiment predictions. \n",
    "classify the text as either \"Positive\" or \"Negative\" based on the probability threshold for the positive class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "714c94c7-c20b-4e8f-92a0-8db87abf4af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_roberta_sentiment(text, tokenizer, model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Analyze sentiment using RoBERTa and classify as Positive, or Negative.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = roberta_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    probs = softmax(logits, dim=-1).numpy()[0]  # Convert logits to probabilities\n",
    "    negative_prob, neutral_prob, positive_prob = probs  # Extract individual probabilities\n",
    "\n",
    "    # Classify based on confidence threshold\n",
    "    if positive_prob >= threshold:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4de2c7-dd33-4471-86bd-fcc99803708a",
   "metadata": {},
   "source": [
    "load the dataset containing feedback and the true sentiment labels. The sentiment analysis function is applied to the feedback texts, and the predictions are stored in a new column. \n",
    "Finally, print a classification report to evaluate the performance of the RoBERTa model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc38b140-23d9-4db7-9f6a-20ee7fbe8fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RoBERTa Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      1.00      0.94       500\n",
      "    Positive       1.00      0.88      0.93       500\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.94      0.94      0.94      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(r\"C:\\Users\\291688\\Downloads\\Sentiment_Analysis_NLP_Model\\channel_partner_feedback.csv\")  # Ensure it has 'text' and 'true_label' columns\n",
    "\n",
    "# Analyze Sentiment for RoBERTa\n",
    "df[\"roberta_model_prediction\"] = df[\"Feedback_Text\"].apply(lambda x: analyze_roberta_sentiment(x, tokenizer, roberta_model))\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\n RoBERTa Model Performance:\")\n",
    "print(classification_report(df[\"Sentiment\"], df[\"roberta_model_prediction\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2def55-33de-4e6a-bcec-cb13e6c2d085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback_ID</th>\n",
       "      <th>Feedback_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>roberta_model_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>The product is well-engineered, leading to hig...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>819</td>\n",
       "      <td>Shipping partners are unreliable, causing delays.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621</td>\n",
       "      <td>Customer service representatives lack technica...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850</td>\n",
       "      <td>The platform's navigation is unintuitive, maki...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201</td>\n",
       "      <td>Promotional discounts have driven more custome...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>289</td>\n",
       "      <td>Customer demand has been steadily increasing f...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>806</td>\n",
       "      <td>Support team is difficult to reach during crit...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>721</td>\n",
       "      <td>Mobile notifications are excessive and cannot ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>57</td>\n",
       "      <td>The company maintains transparency in all tran...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>496</td>\n",
       "      <td>Product stability has led to fewer service int...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feedback_ID                                      Feedback_Text Sentiment  \\\n",
       "0              4  The product is well-engineered, leading to hig...  Positive   \n",
       "1            819  Shipping partners are unreliable, causing delays.  Negative   \n",
       "2            621  Customer service representatives lack technica...  Negative   \n",
       "3            850  The platform's navigation is unintuitive, maki...  Negative   \n",
       "4            201  Promotional discounts have driven more custome...  Positive   \n",
       "..           ...                                                ...       ...   \n",
       "995          289  Customer demand has been steadily increasing f...  Positive   \n",
       "996          806  Support team is difficult to reach during crit...  Negative   \n",
       "997          721  Mobile notifications are excessive and cannot ...  Negative   \n",
       "998           57  The company maintains transparency in all tran...  Positive   \n",
       "999          496  Product stability has led to fewer service int...  Positive   \n",
       "\n",
       "    roberta_model_prediction  \n",
       "0                   Positive  \n",
       "1                   Negative  \n",
       "2                   Negative  \n",
       "3                   Negative  \n",
       "4                   Positive  \n",
       "..                       ...  \n",
       "995                 Positive  \n",
       "996                 Negative  \n",
       "997                 Negative  \n",
       "998                 Negative  \n",
       "999                 Positive  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9d0cd-243d-4bb2-afbf-8d49f6a1c5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
